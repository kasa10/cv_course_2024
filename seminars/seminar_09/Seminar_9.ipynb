{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 9 - Методы построения оптического потока по последовательности изображений\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник - https://habr.com/ru/post/201406/\n",
    "\n",
    "$\\textbf{Task statement}$: Оптический поток (ОП) – изображение видимого движения, представляющее собой сдвиг каждой точки (пикселя) между двумя изображениями.\n",
    "\n",
    "По сути, он представляет собой поле скоростей. Суть ОП в том, что для каждой точки изображения $I_{t_0} (\\vec{r})$ находится такой вектор сдвига $\\delta \\vec{r}$, чтобы было соответсвие между исходной точкой и точкой на следущем фрейме $I_{t_1} (\\vec{r} + \\delta \\vec{r})$. В качестве метрики соответвия берут близость интенсивности пикселей, беря во внимание маленькую разницу по времени между кадрами: $\\delta{t} = t_{1} - t_{0}$. В более точных методах точку можно привязывать к объекту на основе, например, выделения ключевых точек, а также считать градиенты вокруг точки, лапласианы и проч.\n",
    "\n",
    "$\\textbf{For what}$: Определение собственной скорости, Определение локализации, Улучшение методов трекинга объектов, сегментации, Детектирование событий, Сжатие видеопотока и проч.\n",
    "\n",
    "![](data/tennis.png)\n",
    "\n",
    "Разделяют 2 вида оптического потока - плотный (dense) [Farneback method, neural nets], работающий с целым изображением, и выборочный (sparse) [Lucas-Kanade method], работающий с ключевыми точками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-04-18T19:20:49.906526Z",
     "end_time": "2024-04-18T19:20:50.617150Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O data/slow_traffic_small.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T19:20:49.930567Z",
     "end_time": "2024-04-18T19:20:51.253402Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade (sparse)\n",
    "\n",
    "Пусть $I_{1} = I(x, y, t_{1})$ интенсивность в некоторой точке (x, y) на первом изображении (т. е. в момент времени t). На втором изображении эта точка сдвинулась на (dx, dy), при этом прошло время dt, тогда $I_{2} = I(x + dx, y + dx, t_{1} + dt) \\approx I_{1} + I_{x}dx + I_{y}dy +  I_{t}dt$. Из постановки задачи следует, что интенсивность пикселя не изменилась, тогда $I_{1} = I_{2}$. Далее определяем $dx, dy$.\n",
    "\n",
    "Самое простое решение проблемы – алгоритм Лукаса-Канаде. У нас же на изображении объекты размером больше 1 пикселя, значит, скорее всего, в окрестности текущей точки у других точек будут примерно такие же сдвиги. Поэтому мы возьмем окно вокруг этой точки и минимизируем (по МНК) в нем суммарную погрешность с весовыми коэффициентами, распределенными по Гауссу, то есть так, чтобы наибольший вес имели пиксели, ближе всего находящиеся к исследуемому.\n",
    "\n",
    "**Полезные материалы:** \n",
    "- цикл видео-лекций от First Principles of Computer Vision, посвященный Optical Flow и алгоритму Lucas-Kanade: https://youtube.com/playlist?list=PL2zRqk16wsdoYzrWStffqBAoUY8XdvatV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 1\n",
    "\n",
    "В `cv2.calcOpticalFlowPyrLK` есть параметр, отвечающий за ImagePiramyd. Зачем нужна пирамида изображений в случае вычисления оптического потока?\n",
    "\n",
    "**Ответ:**\n",
    "\n",
    "Пирамида изображений используется в алгоритме оптического потока для обеспечения масштабной инвариантности. Это позволяет алгоритму работать с изображениями разного разрешения, что полезно, когда объекты на сцене могут изменять свой размер или удаление от камеры. Путем создания пирамиды изображений мы можем вычислить оптический поток на разных уровнях разрешения, начиная с более крупных объектов на более низком разрешении, а затем уточнять его на более высоких уровнях с более детализированными изображениями. Это улучшает точность вычисления оптического потока и делает алгоритм более устойчивым к изменениям масштаба."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Напишите реализацию Лукаса-Канаде c помощью numpy и cv2. Сравните с реализацией `cv2.calcOpticalFlowPyrLK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T19:20:51.269367Z",
     "end_time": "2024-04-18T19:20:51.296652Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_derivative_x(prevImg, keypoint, winSize):\n",
    "    x, y = np.round(keypoint.ravel()).astype(int)  # Округляем до целых чисел\n",
    "    win_half = winSize[0] // 2\n",
    "    roi = prevImg[y - win_half: y + win_half + 1, x - win_half: x + win_half + 1]\n",
    "    derivative_x = cv2.Sobel(roi, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    return derivative_x\n",
    "\n",
    "def get_derivative_y(prevImg, keypoint, winSize):\n",
    "    x, y = np.round(keypoint.ravel()).astype(int)  # Округляем до целых чисел\n",
    "    win_half = winSize[0] // 2\n",
    "    roi = prevImg[y - win_half: y + win_half + 1, x - win_half: x + win_half + 1]\n",
    "    derivative_y = cv2.Sobel(roi, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    return derivative_y\n",
    "\n",
    "\n",
    "def get_derivative_t(prevImg, nextImg, keypoint, winSize):\n",
    "    x, y = keypoint.ravel()\n",
    "    win_half = winSize[0] // 2\n",
    "    roi_prev = prevImg[int(y) - win_half: int(y) + win_half + 1, int(x) - win_half: int(x) + win_half + 1]\n",
    "    roi_next = nextImg[int(y) - win_half: int(y) + win_half + 1, int(x) - win_half: int(x) + win_half + 1]\n",
    "    derivative_t = roi_next - roi_prev\n",
    "    return derivative_t\n",
    "\n",
    "\n",
    "# arguments like in cv2 lib\n",
    "def my_calcOpticalFlowPyrLK(\n",
    "    prevImg,\n",
    "    nextImg,\n",
    "    prevPts,\n",
    "    nextPts, #None is our case\n",
    "    winSize,\n",
    "    #maxLevel, if you want to be an expert in CV,\n",
    "    #uncomment it and apply in LK method :)\n",
    ") -> np.array:\n",
    "\n",
    "    '''\n",
    "    You should return output vector of 2D points\n",
    "    (with single-precision floating-point coordinates)\n",
    "    containing the calculated new positions of input features in the second image\n",
    "    '''\n",
    "    nextPts = []\n",
    "\n",
    "\n",
    "    for keypoint in prevPts:\n",
    "\n",
    "        derivative_x = get_derivative_x(prevImg, keypoint, winSize)\n",
    "        derivative_y = get_derivative_y(prevImg, keypoint, winSize)\n",
    "        derivative_t = get_derivative_t(prevImg, nextImg, keypoint, winSize)\n",
    "\n",
    "        # find a matrix and solve linear equation system\n",
    "\n",
    "        x, y = keypoint.ravel()\n",
    "\n",
    "        A = np.vstack((derivative_x.flatten(), derivative_y.flatten())).T\n",
    "        b = -derivative_t.flatten()\n",
    "\n",
    "        flow = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "        dx, dy = flow\n",
    "\n",
    "        nextPts.append([x + dx, y + dy])\n",
    "\n",
    "    # return np.array(nextPts)\n",
    "    return np.expand_dims(np.stack(nextPts), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T18:50:57.572792Z",
     "end_time": "2024-04-18T18:50:57.687020Z"
    }
   },
   "source": [
    "### Релизация OpenCV - cv2.calcOpticalFlowPyrLK"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T19:20:51.296652Z",
     "end_time": "2024-04-18T19:20:55.977048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 913/914 [00:04<00:00, 200.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames grabbed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_path = 'data/slow_traffic_small.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('output_LK.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners = 100,\n",
    "    qualityLevel = 0.3,\n",
    "    minDistance = 7,\n",
    "    blockSize = 7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(\n",
    "    #window size\n",
    "    winSize  = (15, 15),\n",
    "    #image piramid\n",
    "    maxLevel = 2,\n",
    "    #after the specified maximum number of iterations criteria.maxCount\n",
    "    #or when the search window moves by less than criteria.epsilon.\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    ")\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "for i in tqdm(range(length)):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        prevImg=old_gray,\n",
    "        nextImg=frame_gray,\n",
    "        prevPts=p0,\n",
    "        nextPts=None,\n",
    "        **lk_params,\n",
    "    )\n",
    "\n",
    "    # Select good points where status is equal 1\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    out.write(img)\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T19:20:55.977048Z",
     "end_time": "2024-04-18T19:20:56.167005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"output_LK.mp4\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Video('output_LK.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"output_LK.mp4\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = 'data/slow_traffic_small.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('output_LK2.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners = 100,\n",
    "    qualityLevel = 0.3,\n",
    "    minDistance = 7,\n",
    "    blockSize = 7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(\n",
    "    #window size\n",
    "    winSize  = (15, 15),\n",
    "    #image piramid\n",
    "    #maxLevel = 2,\n",
    "    #after the specified maximum number of iterations criteria.maxCount\n",
    "    #or when the search window moves by less than criteria.epsilon.\n",
    "    # criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    ")\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "for i in tqdm(range(length)):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n",
    "    nextPts = my_calcOpticalFlowPyrLK(\n",
    "        prevImg=old_gray,\n",
    "        nextImg=frame_gray,\n",
    "        prevPts=p0,\n",
    "        nextPts=None,  # NextPts will be assigned inside the function\n",
    "        winSize=(15,15)\n",
    "    )\n",
    "\n",
    "    if len(good_old) != len(good_new):\n",
    "        print(\"Количество новых и старых точек не совпадает!\")\n",
    "        continue\n",
    "\n",
    "    # Select good points where status is equal 1\n",
    "    # if p1 is not None:\n",
    "    #     good_new = p1[st==1]\n",
    "    #     good_old = p0[st==1]\n",
    "\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    out.write(img)\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T18:30:57.374273Z",
     "end_time": "2024-04-18T18:30:57.432385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 913/914 [00:05<00:00, 166.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames grabbed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IPython.display.Video('output_LK2.mp4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T19:20:56.001251Z",
     "end_time": "2024-04-18T19:21:01.563714Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T19:21:01.563714Z",
     "end_time": "2024-04-18T19:21:01.676411Z"
    }
   },
   "source": [
    "### Вопрос 2\n",
    "\n",
    "Какие проблемы в текущей реализации вы увидели при просмотре результирующего видео? Как их можно устранить?\n",
    "\n",
    "**Ответ:**"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"output_LK2.mp4\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Напишите код, устраняющий одну из проблем, покажите результат до/после."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Farneback (dense)\n",
    "\n",
    "Метод Farneback носит несколько более глобальный характер, чем метод Лукаса-Канаде. Он опирается на предположение о том, что на всем изображении оптический поток будет достаточно гладким."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T19:21:01.584899Z",
     "end_time": "2024-04-18T19:21:14.323391Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 913/914 [00:12<00:00, 72.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames grabbed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('output_Farneback.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "for i in tqdm(range(length)):\n",
    "\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #see arguments here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    prvs = next\n",
    "\n",
    "    out.write(bgr)\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T19:21:14.309369Z",
     "end_time": "2024-04-18T19:21:14.394084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"fix_LK.mp4\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Video('output_Farneback.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
